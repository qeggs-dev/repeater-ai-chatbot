{
    "title": "Repeater LLM Chat Backend Starter",
    "process_title": "Repeater LLM Chat Backend",
    "console_title": "Repeater LLM Chat Backend",
    "exit_title": "Repeater LLM Chat Backend Starter",
    "python_name": {
        "windows": "python",
        "linux": "python3",
        "default": "python3"
    },
    "pip_name": {
        "windows": "pip",
        "linux": "pip3",
        "default": "pip3"
    },
    "venv_prompt": ".venv",
    "script_name": [
        "run_repeater.py"
    ],
    "argument": null,
    "restart": true,
    "requirements": [
        "aiofiles==24.1.0",
        "environs==14.2.0",
        "pydantic==2.11.7",
        "fastapi==0.115.13",
        "python-multipart==0.0.20",
        "loguru==0.7.3",
        "openai==1.90.0",
        "orjson==3.10.18",
        "uvicorn==0.34.3",
        "markdown==3.8.2",
        "playwright==1.56.0",
        "httpx==0.28.1",
        "pyyaml==6.0.2",
        "numpy==2.3.4",
        "python-box==7.3.2",
        "tzdata==2025.2"
    ],
    "run_cmd_need_to_ask": false,
    "run_cmd_ask_default_values": {}
}